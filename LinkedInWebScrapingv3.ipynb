{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "579d7822",
   "metadata": {},
   "source": [
    "# üîç LinkedIn Job Scraper & Title Clustering\n",
    "\n",
    "This project scrapes analyst-related job postings from LinkedIn, extracts job metadata, clusters job titles using embeddings, and stores the results in a SQL Server database.\n",
    "\n",
    "---\n",
    "\n",
    "## üìå Features\n",
    "\n",
    "- Scrapes LinkedIn jobs by title and location\n",
    "- Extracts key job information:  \n",
    "  - Title  \n",
    "  - Company  \n",
    "  - Location  \n",
    "  - Number of applicants  \n",
    "  - Posting date  \n",
    "- Encodes and clusters job titles using SentenceTransformers and KMeans\n",
    "- Assigns standardized job categories to each posting\n",
    "- Stores and retrieves results in/from Microsoft SQL Server\n",
    "\n",
    "---\n",
    "\n",
    "## üß™ Tech Stack\n",
    "\n",
    "- **Python**\n",
    "- **BeautifulSoup** ‚Äì HTML parsing\n",
    "- **Pandas** ‚Äì Data manipulation\n",
    "- **SQLAlchemy + pyodbc** ‚Äì SQL Server integration\n",
    "- **SentenceTransformers** ‚Äì Text embeddings\n",
    "- **Scikit-learn** ‚Äì KMeans clustering\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öôÔ∏è How It Works\n",
    "\n",
    "### 1. Job Scraping\n",
    "\n",
    "Jobs are fetched from LinkedIn using public endpoints and parsed using BeautifulSoup.\n",
    "\n",
    "```python\n",
    "title = 'Analyst'\n",
    "location = 'United Kingdom'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "828374c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import random\n",
    "from urllib.parse import quote_plus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "919784ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Analyst'\n",
    "location='United Kingdom'\n",
    "title_encoded = quote_plus(title)\n",
    "location_encoded = quote_plus(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11597c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: 4205011282\n",
      "Job ID: 4207664202\n",
      "Job ID: 4204943056\n",
      "Job ID: 4200966236\n",
      "Job ID: 4177801948\n",
      "Job ID: 4214760140\n",
      "Job ID: 4207343167\n",
      "Job ID: 4204334816\n",
      "Job ID: 4202997714\n",
      "Job ID: 4209116448\n",
      "Fetched 10 jobs at start=0\n",
      "Job ID: 4209116448\n",
      "Job ID: 4205712236\n",
      "Job ID: 4214779212\n",
      "Job ID: 4204801212\n",
      "Job ID: 4202802795\n",
      "Job ID: 4175856135\n",
      "Job ID: 4214696295\n",
      "Job ID: 4206472637\n",
      "Job ID: 4204361644\n",
      "Job ID: 4201279269\n",
      "Fetched 10 jobs at start=10\n"
     ]
    }
   ],
   "source": [
    "start = 0\n",
    "job_list = []\n",
    "\n",
    "while True:\n",
    "    # Build list URL for paginated results\n",
    "    list_url = (\n",
    "        f\"https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/search\"\n",
    "        f\"?keywords={title_encoded}&location={location_encoded}&start={start}\"\n",
    "    )\n",
    "\n",
    "    # Send request to get job listings\n",
    "    response = requests.get(list_url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "    list_data = response.text\n",
    "    list_soup = BeautifulSoup(list_data, \"html.parser\")\n",
    "\n",
    "    # Find job listing elements\n",
    "    jobs = list_soup.find_all(\"li\")\n",
    "    if not jobs:\n",
    "        break  # No more jobs found\n",
    "\n",
    "    id_list = []\n",
    "    for job in jobs:\n",
    "        base_card_div = job.find(\"div\", {\"class\": \"base-card\"})\n",
    "        if base_card_div:\n",
    "            job_id = base_card_div.get(\"data-entity-urn\").split(\":\")[3]\n",
    "            print(f\"Job ID: {job_id}\")\n",
    "            id_list.append(job_id)\n",
    "\n",
    "    # Visit job detail page for each job\n",
    "    for job_id in id_list:\n",
    "        job_url = f\"https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/{job_id}\"\n",
    "        job_response = requests.get(job_url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "        job_soup = BeautifulSoup(job_response.text, \"html.parser\")\n",
    "\n",
    "        job_post = {}\n",
    "\n",
    "        try:\n",
    "            job_post[\"title\"] = job_soup.find(\"h2\", {\n",
    "                \"class\": \"top-card-layout__title font-sans text-lg papabear:text-xl font-bold leading-open text-color-text mb-0 topcard__title\"\n",
    "            }).text.strip()\n",
    "        except:\n",
    "            job_post[\"title\"] = None\n",
    "\n",
    "        try:\n",
    "            job_post[\"company_name\"] = job_soup.find(\"a\", {\n",
    "                \"class\": \"topcard__org-name-link topcard__flavor--black-link\"\n",
    "            }).text.strip()\n",
    "        except:\n",
    "            job_post[\"company_name\"] = None\n",
    "\n",
    "        try:\n",
    "            job_post[\"location\"] = job_soup.find(\"span\", {\n",
    "                \"class\": \"topcard__flavor topcard__flavor--bullet\"\n",
    "            }).text.strip()\n",
    "        except:\n",
    "            job_post[\"location\"] = None\n",
    "\n",
    "        try:\n",
    "            job_post[\"number_of_applicants\"] = job_soup.find(\"figure\", {\n",
    "                \"class\": \"num-applicants__figure topcard__flavor--metadata topcard__flavor--bullet\"\n",
    "            }).text.strip()\n",
    "        except:\n",
    "            job_post[\"number_of_applicants\"] = None\n",
    "\n",
    "        try:\n",
    "            job_post[\"posted\"] = job_soup.find(\"span\", {\n",
    "                \"class\": \"posted-time-ago__text topcard__flavor--metadata\"\n",
    "            }).text.strip()\n",
    "        except:\n",
    "            job_post[\"posted\"] = None\n",
    "\n",
    "        if any(job_post.values()):  # At least one field is not None/empty\n",
    "         job_list.append(job_post)\n",
    "\n",
    "    print(f\"Fetched {len(jobs)} jobs at start={start}\")\n",
    "    start += 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbd32301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>location</th>\n",
       "      <th>number_of_applicants</th>\n",
       "      <th>posted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Retail Analyst</td>\n",
       "      <td>the LEGO Group</td>\n",
       "      <td>London, England, United Kingdom</td>\n",
       "      <td>None</td>\n",
       "      <td>2 weeks ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Equity Analyst - $2bn AUM Long-Biased Hedge Fund</td>\n",
       "      <td>Mondrian Alpha</td>\n",
       "      <td>Greater London, England, United Kingdom</td>\n",
       "      <td>Over 200 applicants</td>\n",
       "      <td>1 week ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Market Research Analyst</td>\n",
       "      <td>Sony Interactive Entertainment</td>\n",
       "      <td>London, England, United Kingdom</td>\n",
       "      <td>None</td>\n",
       "      <td>2 weeks ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Junior Business Analyst (Regulatory Reporting)</td>\n",
       "      <td>Capgemini</td>\n",
       "      <td>London Area, United Kingdom</td>\n",
       "      <td>Over 200 applicants</td>\n",
       "      <td>3 weeks ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Business Operations | Analyst/Associate | London</td>\n",
       "      <td>Goldman Sachs</td>\n",
       "      <td>London, England, United Kingdom</td>\n",
       "      <td>Over 200 applicants</td>\n",
       "      <td>1 week ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Business Insights Analyst</td>\n",
       "      <td>the LEGO Group</td>\n",
       "      <td>Slough, England, United Kingdom</td>\n",
       "      <td>Over 200 applicants</td>\n",
       "      <td>4 days ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Aston Martin F1 Team</td>\n",
       "      <td>Silverstone, England, United Kingdom</td>\n",
       "      <td>Over 200 applicants</td>\n",
       "      <td>2 weeks ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jr. Procurement Business Analyst</td>\n",
       "      <td>Jefferies</td>\n",
       "      <td>London Area, United Kingdom</td>\n",
       "      <td>Over 200 applicants</td>\n",
       "      <td>3 weeks ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Business Data Analyst</td>\n",
       "      <td>Capgemini</td>\n",
       "      <td>London Area, United Kingdom</td>\n",
       "      <td>Over 200 applicants</td>\n",
       "      <td>3 weeks ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Risk Analyst, UK</td>\n",
       "      <td>Crypto.com</td>\n",
       "      <td>London, England, United Kingdom</td>\n",
       "      <td>None</td>\n",
       "      <td>1 week ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Risk Analyst, UK</td>\n",
       "      <td>Crypto.com</td>\n",
       "      <td>London, England, United Kingdom</td>\n",
       "      <td>None</td>\n",
       "      <td>1 week ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Analyst/Associate Securities Lending Trader</td>\n",
       "      <td>BlackRock</td>\n",
       "      <td>London, England, United Kingdom</td>\n",
       "      <td>None</td>\n",
       "      <td>2 weeks ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Analyst, Sustainable Energy Group</td>\n",
       "      <td>CPP Investments | Investissements RPC</td>\n",
       "      <td>London, England, United Kingdom</td>\n",
       "      <td>Over 200 applicants</td>\n",
       "      <td>4 days ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Investment Banking Analyst</td>\n",
       "      <td>Pearse Partners</td>\n",
       "      <td>London Area, United Kingdom</td>\n",
       "      <td>None</td>\n",
       "      <td>2 weeks ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Ecommerce Analyst</td>\n",
       "      <td>The Dune Group</td>\n",
       "      <td>London, England, United Kingdom</td>\n",
       "      <td>None</td>\n",
       "      <td>3 weeks ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Goldman Sachs Alternatives - Private Equity In...</td>\n",
       "      <td>Goldman Sachs</td>\n",
       "      <td>London, England, United Kingdom</td>\n",
       "      <td>Over 200 applicants</td>\n",
       "      <td>1 week ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2025 Full-Time Analyst Program - EMEA</td>\n",
       "      <td>BlackRock</td>\n",
       "      <td>London, England, United Kingdom</td>\n",
       "      <td>Over 200 applicants</td>\n",
       "      <td>6 days ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Analyst/Associate - Private Equity Secondaries</td>\n",
       "      <td>Neuberger Berman</td>\n",
       "      <td>London, England, United Kingdom</td>\n",
       "      <td>None</td>\n",
       "      <td>2 weeks ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Business Documentation Analyst</td>\n",
       "      <td>Capgemini</td>\n",
       "      <td>London Area, United Kingdom</td>\n",
       "      <td>None</td>\n",
       "      <td>3 weeks ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Merchandise Category Analyst</td>\n",
       "      <td>ASOS.com</td>\n",
       "      <td>London, England, United Kingdom</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0                                      Retail Analyst   \n",
       "1    Equity Analyst - $2bn AUM Long-Biased Hedge Fund   \n",
       "2                             Market Research Analyst   \n",
       "3      Junior Business Analyst (Regulatory Reporting)   \n",
       "4    Business Operations | Analyst/Associate | London   \n",
       "5                           Business Insights Analyst   \n",
       "6                                        Data Analyst   \n",
       "7                    Jr. Procurement Business Analyst   \n",
       "8                               Business Data Analyst   \n",
       "9                                    Risk Analyst, UK   \n",
       "10                                   Risk Analyst, UK   \n",
       "11        Analyst/Associate Securities Lending Trader   \n",
       "12                  Analyst, Sustainable Energy Group   \n",
       "13                         Investment Banking Analyst   \n",
       "14                                  Ecommerce Analyst   \n",
       "15  Goldman Sachs Alternatives - Private Equity In...   \n",
       "16              2025 Full-Time Analyst Program - EMEA   \n",
       "17     Analyst/Associate - Private Equity Secondaries   \n",
       "18                     Business Documentation Analyst   \n",
       "19                       Merchandise Category Analyst   \n",
       "\n",
       "                             company_name  \\\n",
       "0                          the LEGO Group   \n",
       "1                          Mondrian Alpha   \n",
       "2          Sony Interactive Entertainment   \n",
       "3                               Capgemini   \n",
       "4                           Goldman Sachs   \n",
       "5                          the LEGO Group   \n",
       "6                    Aston Martin F1 Team   \n",
       "7                               Jefferies   \n",
       "8                               Capgemini   \n",
       "9                              Crypto.com   \n",
       "10                             Crypto.com   \n",
       "11                              BlackRock   \n",
       "12  CPP Investments | Investissements RPC   \n",
       "13                        Pearse Partners   \n",
       "14                         The Dune Group   \n",
       "15                          Goldman Sachs   \n",
       "16                              BlackRock   \n",
       "17                       Neuberger Berman   \n",
       "18                              Capgemini   \n",
       "19                               ASOS.com   \n",
       "\n",
       "                                   location number_of_applicants       posted  \n",
       "0           London, England, United Kingdom                 None  2 weeks ago  \n",
       "1   Greater London, England, United Kingdom  Over 200 applicants   1 week ago  \n",
       "2           London, England, United Kingdom                 None  2 weeks ago  \n",
       "3               London Area, United Kingdom  Over 200 applicants  3 weeks ago  \n",
       "4           London, England, United Kingdom  Over 200 applicants   1 week ago  \n",
       "5           Slough, England, United Kingdom  Over 200 applicants   4 days ago  \n",
       "6      Silverstone, England, United Kingdom  Over 200 applicants  2 weeks ago  \n",
       "7               London Area, United Kingdom  Over 200 applicants  3 weeks ago  \n",
       "8               London Area, United Kingdom  Over 200 applicants  3 weeks ago  \n",
       "9           London, England, United Kingdom                 None   1 week ago  \n",
       "10          London, England, United Kingdom                 None   1 week ago  \n",
       "11          London, England, United Kingdom                 None  2 weeks ago  \n",
       "12          London, England, United Kingdom  Over 200 applicants   4 days ago  \n",
       "13              London Area, United Kingdom                 None  2 weeks ago  \n",
       "14          London, England, United Kingdom                 None  3 weeks ago  \n",
       "15          London, England, United Kingdom  Over 200 applicants   1 week ago  \n",
       "16          London, England, United Kingdom  Over 200 applicants   6 days ago  \n",
       "17          London, England, United Kingdom                 None  2 weeks ago  \n",
       "18              London Area, United Kingdom                 None  3 weeks ago  \n",
       "19          London, England, United Kingdom                 None         None  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.DataFrame(job_list)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b86c16",
   "metadata": {},
   "source": [
    "### 2.Data Storage\n",
    "Scraped jobs are inserted into a SQL Server database (SampleDB) via SQLAlchemy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66b939e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine,text\n",
    "import pyodbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcd47565",
   "metadata": {},
   "outputs": [],
   "source": [
    "server = \"localhost\\\\SQLEXPRESS\"\n",
    "database = \"SampleDB\"\n",
    "driver = \"ODBC Driver 17 for SQL Server\"\n",
    "engine = create_engine(\n",
    "    f\"mssql+pyodbc://@{server}/{database}?trusted_connection=yes&driver={driver}\"\n",
    ")\n",
    "con = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b979f3c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_sql('LinkedIN_jobs', con=engine, if_exists='append', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef1c18a",
   "metadata": {},
   "source": [
    "### 3. Job Title Clustering\n",
    "Job titles are encoded using a sentence embedding model:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f145ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(df['title'].tolist())\n",
    "\n",
    "kmeans = KMeans(n_clusters=10, random_state=42)\n",
    "df['title_cluster'] = kmeans.fit_predict(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "307ac283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Cluster 0 ---\n",
      "['- Data Analyst - CONTRACT', 'Aerodynamic Data Analyst', 'Associate Data Analyst - Energy and Freight Markets', 'Business Data Analyst', 'Business Data Analyst']\n",
      "\n",
      "--- Cluster 1 ---\n",
      "['2025 Full-Time Analyst Program - EMEA', '2025 Full-Time Analyst Program - EMEA', 'Analyst', 'Analyst - Industrials', 'Analyst - Industrials']\n",
      "\n",
      "--- Cluster 2 ---\n",
      "['Credit Middle office Analyst - Up to ¬£65k + Bonus + Package - London/ Hybrid working', 'Credit Middle office Analyst - Up to ¬£65k + Bonus + Package - London/ Hybrid working', 'FP&A Analyst ‚Äì Real Estate ‚Äì Developments/Construction - ¬£60k + Bonus', 'Graduate Business Modelling Analyst - London - Up to ¬£40,000 + amazing bonus/benefits package', 'Investment Data Analyst ‚Äì Hedge Fund - ¬£65-100k base + bonus']\n",
      "\n",
      "--- Cluster 3 ---\n",
      "['Equity Analyst - $2bn AUM Long-Biased Hedge Fund', 'Equity Analyst - $2bn AUM Long-Biased Hedge Fund', 'Equity Analyst - $2bn AUM Long-Biased Hedge Fund', 'Hedge Fund Credit Analyst', 'L/S Equity Analyst - Multi-Strategy Hedge Fund']\n",
      "\n",
      "--- Cluster 4 ---\n",
      "['Associate', 'Business Analyst ‚Äì London, UK', 'Business Analyst - Travel Domain', 'Business Operations | Analyst/Associate | London', 'Business Operations | Analyst/Associate | London']\n",
      "\n",
      "--- Cluster 5 ---\n",
      "['Goldman Sachs Alternatives - Private Credit Investing - Analyst - London', 'Goldman Sachs Alternatives ‚Äì Private Equity Infrastructure - Analyst - London', 'Goldman Sachs Alternatives ‚Äì Private Equity Infrastructure - Analyst - London', 'Goldman Sachs Alternatives - Private Equity Investing (Climate & Sustainability)- Analyst /Junior Associate - London', 'Goldman Sachs Alternatives - Private Equity Investing (Climate & Sustainability)- Analyst /Junior Associate - London']\n",
      "\n",
      "--- Cluster 6 ---\n",
      "['2025 Blackstone Private Equity Analyst', '2025 Blackstone Private Equity Analyst', 'Analyst, Private Equity', 'Analyst/Associate - Private Equity Secondaries', 'Analyst/Associate - Private Equity Secondaries']\n",
      "\n",
      "--- Cluster 7 ---\n",
      "['2025 Investment Banking Analyst Intern ‚Äì Financial Sponsors Group (London)', 'Analyst, Emerging Markets', 'Analyst, Finance & Risk', 'Analyst, Real Estate Investments', 'Healthcare Associate - Investment Banking']\n",
      "\n",
      "--- Cluster 8 ---\n",
      "['AML & Sanctions Analyst', 'AML/KYC Analyst (12 month FTC)', 'AML/KYC Analyst (12 month FTC)', 'KYC Analyst', 'Trade Analyst - 12 month FTC']\n",
      "\n",
      "--- Cluster 9 ---\n",
      "['Analyst/Associate Securities Lending Trader', 'Analyst/Associate Securities Lending Trader', 'Analyst/Associate Securities Lending Trader', 'Corporate Credit Analyst', 'Counterparty Credit Risk Analyst']\n"
     ]
    }
   ],
   "source": [
    "# Group by cluster and view some example titles\n",
    "for cluster in sorted(df['title_cluster'].unique()):\n",
    "    print(f\"\\n--- Cluster {cluster} ---\")\n",
    "    print(df[df['title_cluster'] == cluster]['title'].head(5).tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85c7909",
   "metadata": {},
   "source": [
    "### 4. Labeling Clusters\n",
    "Clusters are manually mapped to standardized analyst categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4d844a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels = {\n",
    "    0: \"Data Analyst / Quantitative Analyst\",\n",
    "    1: \"Generalist Analyst Programs / Graduate Roles\",\n",
    "    2: \"Financial Planning / Credit / Business Modeling Analyst\",\n",
    "    3: \"Equity / Hedge Fund Analyst\",\n",
    "    4: \"Business Analyst / Associate Roles\",\n",
    "    5: \"Private Credit / Climate / Infrastructure PE Analyst\",\n",
    "    6: \"Private Equity Analyst\",\n",
    "    7: \"Investment Banking / Corporate Finance Analyst\",\n",
    "    8: \"Compliance / KYC / AML Analyst\",\n",
    "    9: \"Trading / Credit Risk Analyst\"\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "df['standard_title'] = df['title_cluster'].map(cluster_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da3fbefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "server = \"localhost\\\\SQLEXPRESS\"\n",
    "database = \"SampleDB\"\n",
    "driver = \"ODBC Driver 17 for SQL Server\"\n",
    "\n",
    "# Use an f-string to inject variables into the connection string\n",
    "cnxn = pyodbc.connect(\n",
    "    f'DRIVER={{{driver}}};SERVER={server};DATABASE={database};Trusted_Connection=yes;'\n",
    ")\n",
    "\n",
    "cursor = cnxn.cursor()\n",
    "cursor.execute(\"SELECT distinct * FROM LinkedIN_jobs\")\n",
    "columns = [column[0] for column in cursor.description]\n",
    "rows = [tuple(row) for row in cursor.fetchall()] \n",
    "\n",
    "# Create DataFrame with column names\n",
    "df = pd.DataFrame(rows, columns=columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fed7b5f",
   "metadata": {},
   "source": [
    "### 5. Final Output\n",
    "The data, now enriched with standard_title, is saved back to SQL Server:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89b6784c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_sql('LinkedIN_jobs', con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df0fac1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìÇ Tables Used\n",
    "\n",
    "- **LinkedIN_jobs** ‚Äì Stores enriched job postings including title, company, location, applicants, post date, cluster label, and standardized job title.\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Future Improvements\n",
    "\n",
    "- Add support for more job functions and geographic regions\n",
    "- Implement database schema versioning (e.g., Alembic)\n",
    "- Automate daily scraping and clustering\n",
    "- Integrate a dashboard or reporting layer (e.g., Streamlit, Power BI)\n",
    "\n",
    "---\n",
    "\n",
    "## üìú Disclaimer\n",
    "\n",
    "This project uses publicly accessible LinkedIn endpoints for educational and research purposes only.  \n",
    "Please use it responsibly and ensure compliance with [LinkedIn‚Äôs Terms of Service](https://www.linkedin.com/legal/user-agreement).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
